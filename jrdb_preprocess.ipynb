{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 13:52:25.840847: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-11 13:52:26.215590: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-11 13:52:26.218776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 13:52:27.508810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import json\n",
    "import os\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"/home/pbr-student/personal/thesis/jrdb/train_dataset_with_activity\" #/labels/labels_2d_pose_stitched_coco/\"\n",
    "scene = \"bytes-cafe-2019-02-07_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from human scene transformer, data subfolder\n",
    "def get_file_handle(path, mode='rt'):\n",
    "  file_handle = open(path, mode)\n",
    "  return file_handle\n",
    "scene_data_file = get_file_handle(\n",
    "      os.path.join(input_path, 'labels', 'labels_3d', scene + '.json')\n",
    "  )\n",
    "\n",
    "# get agents_dict_from_detections\n",
    "scene_data = json.load(scene_data_file)\n",
    "agents = collections.defaultdict(list)\n",
    "for frame in scene_data['labels']:\n",
    "    ts = int(frame.split('.')[0])\n",
    "    for det in scene_data['labels'][frame]:\n",
    "      agents[det['label_id']].append((ts, det))\n",
    "agents_dict = agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_agents_features_with_box\n",
    "max_distance_to_robot = 10\n",
    "agents_pos_dict = collections.defaultdict(dict)\n",
    "for agent_id, agent_data in agents_dict.items():\n",
    "    for (ts, agent_instance) in agent_data:\n",
    "        if agent_instance['attributes']['distance'] <= max_distance_to_robot:\n",
    "            agents_pos_dict[(ts, agent_id)] = {\n",
    "                'p': np.array([agent_instance['box']['cx'],\n",
    "                                agent_instance['box']['cy'],\n",
    "                                agent_instance['box']['cz']]),\n",
    "                # rotation angle is relative to negatiev x axis of robot\n",
    "                'yaw': np.pi - agent_instance['box']['rot_z'],\n",
    "                'l': agent_instance['box']['l'],\n",
    "                'w': agent_instance['box']['w'],\n",
    "                'h': agent_instance['box']['h']\n",
    "            }\n",
    "agents_features = agents_pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents_df = pd.DataFrame.from_dict(\n",
    "        agents_features, orient='index'\n",
    "    ).rename_axis(['timestep', 'id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2764, 'track_id': 8, 'image_id': 542, 'category_id': 1, 'is_crowd': 0, 'keypoints': [563.57, -178.91, 0, 587.46, -136.51, 0, 561.96, -134.31, 0, 568.35, -1.95, 0, 608.45, -29.85, 0, 648.95, -9.85, 0, 558.85, 133.25, 1, 715.95, 128.7, 1, 639.5, 234.4, 1, 463.85, 198.15, 2, 636.48, 268.25, 1, 644.3, 269.27, 1, 618.6, 268.95, 2, 661.1, 468.55, 0, 525.05, 476.1, 2, 703.6, 636.2, 0, 506.5, 660.25, 0], 'num_keypoints': 17}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m frame \u001b[39min\u001b[39;00m scene_data[\u001b[39m'\u001b[39m\u001b[39mannotations\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mprint\u001b[39m(frame)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     ts \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(frame\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m det \u001b[39min\u001b[39;00m scene_data[\u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m][frame]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         agents_keypoints[(ts, det[\u001b[39m'\u001b[39m\u001b[39mlabel_id\u001b[39m\u001b[39m'\u001b[39m])] \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/pbr-student/personal/thesis/test/PedestrianTrajectoryPrediction/jrdb_preprocess.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mkeypoints\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39marray(det[\u001b[39m'\u001b[39m\u001b[39mkeypoints\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreshape(\u001b[39m33\u001b[39m, \u001b[39m3\u001b[39m)}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# get agents keypoints\n",
    "keypoint_path = os.path.join(input_path, 'labels', 'labels_2d_pose_coco')\n",
    "scene_data_file = get_file_handle(os.path.join(keypoint_path, scene + '_image0.json'))\n",
    "scene_data = json.load(scene_data_file)\n",
    "\n",
    "agents_keypoints = collections.defaultdict(dict)\n",
    "\n",
    "for frame in scene_data['annotations']:\n",
    "    print(frame)\n",
    "    ts = int(frame.split('.')[0])\n",
    "    for det in scene_data['labels'][frame]:\n",
    "        agents_keypoints[(ts, det['label_id'])] = {\n",
    "            'keypoints': np.array(det['keypoints']).reshape(33, 3)}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
